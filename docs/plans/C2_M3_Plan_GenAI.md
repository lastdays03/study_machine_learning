# í•™ìŠµ ê³„íšì„œ (Study Plan): Course 2 Module 3 - Transformers & GenAI

**Status**: ğŸ“… Planned
**Created**: 2026-01-05
**Goal**: í˜„ëŒ€ ìì—°ì–´ ì²˜ë¦¬ì˜ í•µì‹¬ì¸ íŠ¸ëœìŠ¤í¬ë¨¸ êµ¬ì¡°ë¥¼ ì´í•´í•˜ê³ , LLMì„ í™œìš©í•œ ì‘ìš© ì„œë¹„ìŠ¤(ì±—ë´‡, RAG)ë¥¼ êµ¬í˜„í•œë‹¤.

---

## ğŸ¯ í•µì‹¬ ëª©í‘œ (Deep Objective)
**"Attention Is All You Need"**
- [ ] What: Self-Attention, BERT/GPT íŒŒì¸íŠœë‹, RAG(ê²€ìƒ‰ ì¦ê°• ìƒì„±).
- [ ] Why: ë‹¨ìˆœ ì˜ˆì¸¡ ëª¨ë¸ì„ ë„˜ì–´, ì¸ê°„ì˜ ì–¸ì–´ë¥¼ ì´í•´í•˜ê³  ìƒì„±í•˜ëŠ” AIë¥¼ ë‹¤ë£¨ê¸° ìœ„í•´.
- [ ] How: [HuggingFace ê°•ì¢Œ, LangChain ê³µì‹ ë¬¸ì„œ]

---

## ğŸ“… ì»¤ë¦¬í˜ëŸ¼ (Curriculum)

### Session 1: íŠ¸ëœìŠ¤í¬ë¨¸ì˜ ì‹¬ì¥ (Transformer Architecture)
**Focus**: Attention Mechanism, Encoder-Decoder

#### âœ… ì‹¬ì¸µ ë§ˆìŠ¤í„° ì²´í¬ë¦¬ìŠ¤íŠ¸
1.  **Theory (Feynman Test)**
    - [ ] **Self-Attention**: "ë¬¸ì¥ ì† ë‹¨ì–´ë“¤ì´ ì„œë¡œ ì–´ë–¤ ê´€ê³„ì¸ì§€ ì£¼ëª©í•œë‹¤"ëŠ” ì˜ë¯¸ ì„¤ëª….
    - [ ] **Multi-Head Attention**: ì—¬ëŸ¬ ê°œì˜ ê´€ì (Head)ì—ì„œ ë¬¸ì¥ì„ ë¶„ì„í•˜ëŠ” ì´ìœ .
    - [ ] **Feynman Summary**: íŠ¸ëœìŠ¤í¬ë¨¸ë¥¼ "ë‹¨ì–´ë“¤ì˜ íšŒì˜ ì‹œê°„"ìœ¼ë¡œ ë¹„ìœ .
2.  **Practice (Break & Fix)**
    - [ ] **Break**: Attention Maskë¥¼ ì œê±°í–ˆì„ ë•Œ Decoderê°€ ë¯¸ë˜ ë‹¨ì–´ë¥¼ ì°¸ì¡°(Cheating)í•˜ëŠ” í˜„ìƒ í™•ì¸.
3.  **Implementation (Output)**
    - [ ] `notebooks/course_2/C2_M3_Exp_Attention_Viz.ipynb` ìƒì„± (Attention Score ì‹œê°í™”).

### Session 2: ê±°ì¸ë“¤ì˜ ì–´ê¹¨ ìœ„ì—ì„œ (Transfer Learning & LLM)
**Focus**: HuggingFace, Fine-tuning

#### âœ… ì‹¬ì¸µ ë§ˆìŠ¤í„° ì²´í¬ë¦¬ìŠ¤íŠ¸
1.  **Theory (Feynman Test)**
    - [ ] **Pre-training vs Fine-tuning**: "ì¼ë°˜ ìƒì‹ ê³µë¶€(Pre-training)"ì™€ "ì „ê³µ ì‹¬í™” ê³µë¶€(Fine-tuning)" ë¹„ìœ .
    - [ ] **Tokenizer**: LLMì´ í…ìŠ¤íŠ¸ë¥¼ ìˆ«ìë¡œ ìª¼ê°œëŠ” ë°©ì‹ (BPE, Subword).
2.  **Practice (Break & Fix)**
    - [ ] **Break**: Tokenizer ì„¤ì •ì„ ì˜ëª» ë§ì¶°(ìµœëŒ€ ê¸¸ì´ ì œí•œ ë“±) ëª¨ë¸ ì„±ëŠ¥ì´ ê¸‰ë½í•˜ëŠ” ìƒí™© ì¬í˜„.
3.  **Implementation (Output)**
    - [ ] `notebooks/course_2/C2_M3_Project_FineTuning.ipynb` ìƒì„± (BERTë¡œ ë‰´ìŠ¤ ë¶„ë¥˜í•˜ê¸°).

### Session 3: ì§€ì‹ì˜ í™•ì¥ (RAG System)
**Focus**: Vector DB, LangChain

#### âœ… ì‹¬ì¸µ ë§ˆìŠ¤í„° ì²´í¬ë¦¬ìŠ¤íŠ¸
1.  **Theory (Feynman Test)**
    - [ ] **Embeddings**: ë¬¸ì¥ì˜ ì˜ë¯¸ë¥¼ ë²¡í„° ê³µê°„ ì¢Œí‘œë¡œ ë³€í™˜í•˜ëŠ” ì›ë¦¬.
    - [ ] **RAG Flow**: ì§ˆë¬¸ -> ê²€ìƒ‰(Retriever) -> ë¬¸ë§¥ ì£¼ì…(Augment) -> ë‹µë³€(Generation).
2.  **Practice (Break & Fix)**
    - [ ] **Break**: ì—‰ëš±í•œ ë¬¸ì„œ(Chunk)ê°€ ê²€ìƒ‰ë˜ì—ˆì„ ë•Œ LLMì´ í™˜ê°(Hallucination)ì„ ì¼ìœ¼í‚¤ëŠ” í˜„ìƒ í…ŒìŠ¤íŠ¸.
3.  **Implementation (Output)**
    - [ ] `notebooks/course_2/C2_M3_Project_RAG_Chatbot.ipynb` ìƒì„± (PDF ë¬¸ì„œ ê¸°ë°˜ Q&A ë´‡).

---

## ğŸ“ í•™ìŠµ ë¡œê·¸ (Learning Log / Notes)

### Session 1 Notes (Transformer)
- ğŸ“„ **Detail Note**: [C2_M3_Note_Transformer.md](../study_notes/C2_M3_Note_Transformer.md)

### Session 2 Notes (LLM)
- ğŸ“„ **Detail Note**: [C2_M3_Note_LLM_FineTuning.md](../study_notes/C2_M3_Note_LLM_FineTuning.md)

### Session 3 Notes (RAG)
- ğŸ“„ **Detail Note**: [C2_M3_Note_RAG.md](../study_notes/C2_M3_Note_RAG.md)
