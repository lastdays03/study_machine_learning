# 4주차 Session 1.5: 데이터 전처리 심화 (Encoding & Scaling)

> **목표**: 머신러닝 모델이 데이터를 잘 이해할 수 있도록, 문자를 숫자로 바꾸고(**인코딩**), 데이터의 크기를 맞추는(**스케일링**) 필수 전처리 기법을 익힙니다.

## 1. 인코딩 (Encoding): 문자를 숫자로 변환

컴퓨터는 'Male', 'Female' 같은 글자를 이해하지 못합니다. 모든 데이터는 반드시 **숫자**여야 합니다.

### 1) 레이블 인코딩 (Label Encoding)
*   범주(Category)에 0부터 시작하는 고유번호를 붙입니다.
*   **예시**:
    *   `Male` -> `0`
    *   `Female` -> `1`
    *   `TV` -> `0`, `Fridge` -> `1`, `Microwave` -> `2`
*   **주의**: 숫자의 **크기**가 의미를 가질 수 있어, 순서가 없는 데이터(명목형)에 쓰면 모델이 오해할 수 있습니다. (예: TV < Fridge ??)
*   **사용**: 트리 계열 알고리즘(Random Forest 등)에서는 괜찮습니다.

### 2) 원-핫 인코딩 (One-Hot Encoding)
*   해당하는 값만 `1`이고 나머지는 `0`인 긴 배열을 만듭니다.
*   **예시**: `TV`, `Fridge`, `Microwave`
    *   `TV` -> `[1, 0, 0]`
    *   `Fridge` -> `[0, 1, 0]`
*   **장점**: 숫자의 크기 오해를 없앱니다.
*   **단점**: 데이터의 컬럼(차원)이 늘어납니다.

---

## 2. 피처 스케일링 (Feature Scaling): 단위 맞추기

데이터마다 단위(Scale)가 다르면, 값이 큰 쪽에 모델이 휘둘릴 수 있습니다.
*   **예시**:
    *   키(Height): 170cm, 180cm (차이 10)
    *   시력(Vision): 0.5, 1.5 (차이 1)
    *   실제로는 시력 1.0 차이가 엄청 큰 것이지만, 숫자는 키(10)가 더 크므로 모델은 키를 더 중요하게 볼 수 있습니다.

### 1) 표준화 (StandardScaler)
*   데이터를 **평균이 0, 분산이 1**인 정규분포 형태로 만듭니다.
*   $$ z = \frac{x - mean}{std} $$
*   **특징**: 이상치(Outlier)에 덜 민감하며, 회귀 모델이나 SVM, 신경망에 필수적입니다.

### 2) 정규화 (MinMaxScaler)
*   데이터를 **0과 1 사이**로 압축합니다.
*   $$ x_{new} = \frac{x - min}{max - min} $$
*   **특징**: 이미지가 0~255 값을 가질 때 주로 사용합니다.
