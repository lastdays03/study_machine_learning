# 4주차 Session 3: 분류 모델 평가 지표 (Evaluation Metrics)

> **목표**: 분류 모델의 성능을 단순히 '정확도'로만 판단할 때의 위험성을 이해하고, 상황에 맞는 올바른 평가 지표(**오차 행렬, 정밀도, 재현율, F1-Score, AUC**)를 선택하는 법을 배웁니다.

## 1. 정확도(Accuracy)의 함정

데이터가 불균형할 때(Imbalaced Data), 정확도는 왜곡될 수 있습니다.
*   **예시**: 암 환자 데이터 100명 중 실제 환자는 1명뿐.
    *   모델이 무조건 "정상"이라고만 찍어도 정확도는 **99%**가 나옴.
    *   하지만 이 모델은 암 환자를 한 명도 못 찾으므로 쓸모가 없음.

---

## 2. 오차 행렬 (Confusion Matrix)

예측 결과와 실제 정답을 4가지 경우로 나눈 표입니다.

|                       |                  실제 Negative (0)                  |                 실제 Positive (1)                  |
| :-------------------: | :-------------------------------------------------: | :------------------------------------------------: |
| **예측 Negative (0)** |  **TN** (True Negative) <br> 정답(음성)을 잘 맞춤   | **FN** (False Negative) <br> 양성인데 놓침 (심각!) |
| **예측 Positive (1)** | **FP** (False Positive) <br> 음성인데 양성이라 우김 |  **TP** (True Positive) <br> 정답(양성)을 잘 맞춤  |

---

## 3. 정밀도(Precision)와 재현율(Recall)

### 정밀도 (Precision) = $\frac{TP}{TP + FP}$
*   모델이 **"양성(1)"이라고 예측한 것 중** 실제 양성의 비율.
*   **중요한 경우**: 스팸 메일 필터 (정상 메일을 스팸이라 분류하면 안 됨 - **FP를 줄여야 함**)

### 재현율 (Recall) = $\frac{TP}{TP + FN}$
*   **실제 "양성(1)"인 데이터 중** 모델이 찾아낸 비율.
*   다른 말로 **민감도(Sensitivity)**.
*   **중요한 경우**: 암 환자 예측, 금융 사기 탐지 (실제 환자/사기꾼을 놓치면 안 됨 - **FN을 줄여야 함**)

---

## 4. F1-Score

정밀도와 재현율의 **조화 평균**입니다. 두 지표가 어느 한쪽으로 치우치지 않고 골고루 좋을 때 높은 값을 가집니다.

$$ F1 = 2 \times \frac{\text{Precision} \times \text{Recall}}{\text{Precision} + \text{Recall}} $$

---

## 5. ROC 곡선과 AUC

*   **ROC Curve**: 임계값(Threshold)을 0부터 1까지 변화시키면서 모델의 성능 변화(TPR vs FPR)를 그린 곡선.
*   **AUC (Area Under Curve)**: ROC 곡선 아래의 면적.
    *   1에 가까울수록 완벽한 모델.
    *   0.5면 찍는 수준.
