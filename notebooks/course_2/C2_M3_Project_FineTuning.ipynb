{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# C2 M3 Project FineTuning\n",
                "**Course**: Course 2 (Master Class)\n",
                "**Workflow**: `data-notebook-refiner`\n",
                "\n",
                "---\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# üîß Setup & Imports\n",
                "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
                "import torch\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Prepare Dataset (HuggingFace Style)\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "/Users/bagjongman/dev/workspace/study/python/study_machine_learning/.venv/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
                        "  from .autonotebook import tqdm as notebook_tqdm\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Tokenized Input: torch.Size([3, 6])\n"
                    ]
                }
            ],
            "source": [
                "\n",
                "model_name = 'distilbert-base-uncased'\n",
                "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
                "\n",
                "sentences = ['I love this movie', 'This is terrible', 'Best performance ever']\n",
                "labels = [1, 0, 1]\n",
                "\n",
                "inputs = tokenizer(sentences, padding=True, truncation=True, return_tensors='pt')\n",
                "labels = torch.tensor(labels)\n",
                "print('Tokenized Input:', inputs['input_ids'].shape)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Model & Loss\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
                        "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Loss: 0.74005526304245\n",
                        "Logits: tensor([[-0.0864, -0.2746],\n",
                        "        [-0.0856, -0.2732],\n",
                        "        [-0.0641, -0.3120]], grad_fn=<AddmmBackward0>)\n"
                    ]
                }
            ],
            "source": [
                "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=2)\n",
                "\n",
                "outputs = model(**inputs, labels=labels)\n",
                "print('Loss:', outputs.loss.item())\n",
                "print('Logits:', outputs.logits)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "\n",
                "---\n",
                "## üìù Key Takeaways & Insights\n",
                "*   **What did we learn?**\n",
                "    *   (Ïó¨Í∏∞Ïóê ÌïµÏã¨ Î∞∞Ïö¥ Ï†êÏùÑ Í∏∞Î°ùÌïòÏÑ∏Ïöî)\n",
                "*   **Next Steps**:\n",
                "    *   (Îã§Ïùå ÌïôÏäµ Îã®Í≥Ñ)\n"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": ".venv",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.13.5"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}